{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n# Predict TripAdvisor Rating\n## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n**По ходу задачи:**\n* Прокачаем работу с pandas\n* Научимся работать с Kaggle Notebooks\n* Поймем как делать предобработку различных данных\n* Научимся работать с пропущенными данными (Nan)\n* Познакомимся с различными видами кодирования признаков\n* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n* И совсем немного затронем ML\n* И многое другое...   \n\n\n\n### И самое важное, все это вы сможете сделать самостоятельно!\n\n*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \nВы можете использовать его как основу для построения своего решения.\n\n> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \nТакже baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n\nВ контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются).","metadata":{}},{"cell_type":"markdown","source":"# import","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime as dt\nimport json\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-10-11T10:06:31.788261Z","iopub.execute_input":"2021-10-11T10:06:31.788836Z","iopub.status.idle":"2021-10-11T10:06:31.810667Z","shell.execute_reply.started":"2021-10-11T10:06:31.788769Z","shell.execute_reply":"2021-10-11T10:06:31.809528Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:31.813220Z","iopub.execute_input":"2021-10-11T10:06:31.813543Z","iopub.status.idle":"2021-10-11T10:06:31.822173Z","shell.execute_reply.started":"2021-10-11T10:06:31.813493Z","shell.execute_reply":"2021-10-11T10:06:31.820891Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:31.824009Z","iopub.execute_input":"2021-10-11T10:06:31.824737Z","iopub.status.idle":"2021-10-11T10:06:35.693683Z","shell.execute_reply.started":"2021-10-11T10:06:31.824669Z","shell.execute_reply":"2021-10-11T10:06:35.692484Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# DATA","metadata":{}},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/'\ndf_train = pd.read_csv(DATA_DIR+'sf-dst-restaurant-rating/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'sf-dst-restaurant-rating/kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'sf-dst-restaurant-rating/sample_submission.csv')\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-10-11T10:06:35.695418Z","iopub.execute_input":"2021-10-11T10:06:35.695754Z","iopub.status.idle":"2021-10-11T10:06:36.008886Z","shell.execute_reply.started":"2021-10-11T10:06:35.695694Z","shell.execute_reply":"2021-10-11T10:06:36.007612Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"df_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.012706Z","iopub.execute_input":"2021-10-11T10:06:36.013148Z","iopub.status.idle":"2021-10-11T10:06:36.056513Z","shell.execute_reply.started":"2021-10-11T10:06:36.013031Z","shell.execute_reply":"2021-10-11T10:06:36.055224Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"df_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.060773Z","iopub.execute_input":"2021-10-11T10:06:36.061113Z","iopub.status.idle":"2021-10-11T10:06:36.083185Z","shell.execute_reply.started":"2021-10-11T10:06:36.061062Z","shell.execute_reply":"2021-10-11T10:06:36.081742Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.085097Z","iopub.execute_input":"2021-10-11T10:06:36.085429Z","iopub.status.idle":"2021-10-11T10:06:36.105961Z","shell.execute_reply.started":"2021-10-11T10:06:36.085374Z","shell.execute_reply":"2021-10-11T10:06:36.104996Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df_test.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.107569Z","iopub.execute_input":"2021-10-11T10:06:36.107880Z","iopub.status.idle":"2021-10-11T10:06:36.129178Z","shell.execute_reply.started":"2021-10-11T10:06:36.107816Z","shell.execute_reply":"2021-10-11T10:06:36.127919Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"sample_submission.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.130655Z","iopub.execute_input":"2021-10-11T10:06:36.131035Z","iopub.status.idle":"2021-10-11T10:06:36.148986Z","shell.execute_reply.started":"2021-10-11T10:06:36.130975Z","shell.execute_reply":"2021-10-11T10:06:36.148008Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"sample_submission.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.150784Z","iopub.execute_input":"2021-10-11T10:06:36.151115Z","iopub.status.idle":"2021-10-11T10:06:36.168630Z","shell.execute_reply.started":"2021-10-11T10:06:36.151064Z","shell.execute_reply":"2021-10-11T10:06:36.167331Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.170805Z","iopub.execute_input":"2021-10-11T10:06:36.171115Z","iopub.status.idle":"2021-10-11T10:06:36.222228Z","shell.execute_reply.started":"2021-10-11T10:06:36.171065Z","shell.execute_reply":"2021-10-11T10:06:36.221030Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.224122Z","iopub.execute_input":"2021-10-11T10:06:36.224737Z","iopub.status.idle":"2021-10-11T10:06:36.275289Z","shell.execute_reply.started":"2021-10-11T10:06:36.224625Z","shell.execute_reply":"2021-10-11T10:06:36.273907Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана","metadata":{}},{"cell_type":"code","source":"data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.277346Z","iopub.execute_input":"2021-10-11T10:06:36.277784Z","iopub.status.idle":"2021-10-11T10:06:36.302878Z","shell.execute_reply.started":"2021-10-11T10:06:36.277707Z","shell.execute_reply":"2021-10-11T10:06:36.301900Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"data.Reviews[1]","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.304571Z","iopub.execute_input":"2021-10-11T10:06:36.304990Z","iopub.status.idle":"2021-10-11T10:06:36.319668Z","shell.execute_reply.started":"2021-10-11T10:06:36.304925Z","shell.execute_reply":"2021-10-11T10:06:36.318785Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"Как видим, большинство признаков у нас требует очистки и предварительной обработки.","metadata":{}},{"cell_type":"markdown","source":"# Cleaning and Prepping Data\nОбычно данные содержат в себе кучу мусора, который необходимо почистить, для того чтобы привести их в приемлемый формат. Чистка данных — это необходимый этап решения почти любой реальной задачи.   \n![](https://analyticsindiamag.com/wp-content/uploads/2018/01/data-cleaning.png)","metadata":{}},{"cell_type":"markdown","source":"## 1. Обработка NAN \nУ наличия пропусков могут быть разные причины, но пропуски нужно либо заполнить, либо исключить из набора полностью. Но с пропусками нужно быть внимательным, **даже отсутствие информации может быть важным признаком!**   \nПо этому перед обработкой NAN лучше вынести информацию о наличии пропуска как отдельный признак ","metadata":{}},{"cell_type":"code","source":"# Для примера я возьму столбец Number of Reviews\ndata['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.321293Z","iopub.execute_input":"2021-10-11T10:06:36.321751Z","iopub.status.idle":"2021-10-11T10:06:36.330889Z","shell.execute_reply.started":"2021-10-11T10:06:36.321661Z","shell.execute_reply":"2021-10-11T10:06:36.329353Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"data['Number_of_Reviews_isNAN']","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.332511Z","iopub.execute_input":"2021-10-11T10:06:36.333028Z","iopub.status.idle":"2021-10-11T10:06:36.347529Z","shell.execute_reply.started":"2021-10-11T10:06:36.332842Z","shell.execute_reply":"2021-10-11T10:06:36.346614Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# Далее заполняем пропуски 0, вы можете попробовать заполнением средним или средним по городу и тд...\ndata['Number of Reviews'].fillna(0, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.349376Z","iopub.execute_input":"2021-10-11T10:06:36.349736Z","iopub.status.idle":"2021-10-11T10:06:36.355383Z","shell.execute_reply.started":"2021-10-11T10:06:36.349686Z","shell.execute_reply":"2021-10-11T10:06:36.354574Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### 2. Обработка признаков\nДля начала посмотрим какие признаки у нас могут быть категориальными.","metadata":{}},{"cell_type":"code","source":"data.nunique(dropna=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.356582Z","iopub.execute_input":"2021-10-11T10:06:36.357075Z","iopub.status.idle":"2021-10-11T10:06:36.491783Z","shell.execute_reply.started":"2021-10-11T10:06:36.357017Z","shell.execute_reply":"2021-10-11T10:06:36.490762Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"Какие признаки можно считать категориальными?","metadata":{}},{"cell_type":"markdown","source":"Для кодирования категориальных признаков есть множество подходов:\n* Label Encoding\n* One-Hot Encoding\n* Target Encoding\n* Hashing\n\nВыбор кодирования зависит от признака и выбраной модели.\nНе будем сейчас сильно погружаться в эту тематику, давайте посмотрим лучше пример с One-Hot Encoding:\n![](https://i.imgur.com/mtimFxh.png)","metadata":{}},{"cell_type":"code","source":"# для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\ndata = pd.get_dummies(data, columns=[ 'City',], dummy_na=True)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.493105Z","iopub.execute_input":"2021-10-11T10:06:36.493412Z","iopub.status.idle":"2021-10-11T10:06:36.530157Z","shell.execute_reply.started":"2021-10-11T10:06:36.493360Z","shell.execute_reply":"2021-10-11T10:06:36.529297Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"data.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.531939Z","iopub.execute_input":"2021-10-11T10:06:36.532248Z","iopub.status.idle":"2021-10-11T10:06:36.565822Z","shell.execute_reply.started":"2021-10-11T10:06:36.532195Z","shell.execute_reply":"2021-10-11T10:06:36.565014Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"data.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.567672Z","iopub.execute_input":"2021-10-11T10:06:36.567943Z","iopub.status.idle":"2021-10-11T10:06:36.610965Z","shell.execute_reply.started":"2021-10-11T10:06:36.567892Z","shell.execute_reply":"2021-10-11T10:06:36.610169Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"#### Возьмем следующий признак \"Price Range\".","metadata":{}},{"cell_type":"code","source":"data['Price Range'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.612168Z","iopub.execute_input":"2021-10-11T10:06:36.612606Z","iopub.status.idle":"2021-10-11T10:06:36.632060Z","shell.execute_reply.started":"2021-10-11T10:06:36.612541Z","shell.execute_reply":"2021-10-11T10:06:36.631025Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"По описанию 'Price Range' это - Цены в ресторане.  \nИх можно поставить по возрастанию (значит это не категориальный признак). А это значит, что их можно заменить последовательными числами, например 1,2,3  \n*Попробуйте сделать обработку этого признака уже самостоятельно!*","metadata":{}},{"cell_type":"code","source":"# Ваша обработка 'Price Range'","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.633808Z","iopub.execute_input":"2021-10-11T10:06:36.634241Z","iopub.status.idle":"2021-10-11T10:06:36.641712Z","shell.execute_reply.started":"2021-10-11T10:06:36.634177Z","shell.execute_reply":"2021-10-11T10:06:36.640487Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"> Для некоторых алгоритмов МЛ даже для не категориальных признаков можно применить One-Hot Encoding, и это может улучшить качество модели. Пробуйте разные подходы к кодированию признака - никто не знает заранее, что может взлететь.","metadata":{}},{"cell_type":"markdown","source":"### Обработать другие признаки вы должны самостоятельно!\nДля обработки других признаков вам возможно придется даже написать свою функцию, а может даже и не одну, но в этом и есть ваша практика в этом модуле!     \nСледуя подсказкам в модуле вы сможете более подробно узнать, как сделать эти приобразования.","metadata":{}},{"cell_type":"code","source":"# тут ваш код на обработку других признаков\n# .....","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.643233Z","iopub.execute_input":"2021-10-11T10:06:36.643597Z","iopub.status.idle":"2021-10-11T10:06:36.652929Z","shell.execute_reply.started":"2021-10-11T10:06:36.643541Z","shell.execute_reply":"2021-10-11T10:06:36.651813Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"![](https://cs10.pikabu.ru/post_img/2018/09/06/11/1536261023140110012.jpg)","metadata":{}},{"cell_type":"markdown","source":"# EDA \n[Exploratory Data Analysis](https://ru.wikipedia.org/wiki/Разведочный_анализ_данных) - Анализ данных\nНа этом этапе мы строим графики, ищем закономерности, аномалии, выбросы или связи между признаками.\nВ общем цель этого этапа понять, что эти данные могут нам дать и как признаки могут быть взаимосвязаны между собой.\nПонимание изначальных признаков позволит сгенерировать новые, более сильные и, тем самым, сделать нашу модель лучше.\n![](https://miro.medium.com/max/2598/1*RXdMb7Uk6mGqWqPguHULaQ.png)","metadata":{}},{"cell_type":"markdown","source":"### Посмотрим распределение признака","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (10,7)\ndf_train['Ranking'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:36.654833Z","iopub.execute_input":"2021-10-11T10:06:36.655391Z","iopub.status.idle":"2021-10-11T10:06:37.169296Z","shell.execute_reply.started":"2021-10-11T10:06:36.655281Z","shell.execute_reply":"2021-10-11T10:06:37.168649Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"У нас много ресторанов, которые не дотягивают и до 2500 места в своем городе, а что там по городам?","metadata":{}},{"cell_type":"code","source":"df_train['City'].value_counts(ascending=True).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:37.170880Z","iopub.execute_input":"2021-10-11T10:06:37.171437Z","iopub.status.idle":"2021-10-11T10:06:37.662838Z","shell.execute_reply.started":"2021-10-11T10:06:37.171368Z","shell.execute_reply":"2021-10-11T10:06:37.661622Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"А кто-то говорил, что французы любят поесть=) Посмотрим, как изменится распределение в большом городе:","metadata":{}},{"cell_type":"code","source":"df_train['Ranking'][df_train['City'] =='London'].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:37.664591Z","iopub.execute_input":"2021-10-11T10:06:37.665173Z","iopub.status.idle":"2021-10-11T10:06:38.180977Z","shell.execute_reply.started":"2021-10-11T10:06:37.665084Z","shell.execute_reply":"2021-10-11T10:06:38.179026Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Нормируем ранк ресторана относительно максимального ранга в его городе\ncity_max_rank=df_train[['Ranking','City']].groupby(by='City').max()\ncity_max_rank.columns=['max_rank']\ndf_train=df_train.merge(city_max_rank, how='left', on='City')\ndf_train['Ranking']=df_train['Ranking']/df_train['max_rank']\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:38.183546Z","iopub.execute_input":"2021-10-11T10:06:38.184152Z","iopub.status.idle":"2021-10-11T10:06:38.246675Z","shell.execute_reply.started":"2021-10-11T10:06:38.184065Z","shell.execute_reply":"2021-10-11T10:06:38.245972Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# посмотрим на топ 10 городов\n\nfor x in (df_train['City'].value_counts())[0:10].index:\n#     df_train['Ranking'][df_train['City'] == x].hist(bins=100)\n    df_train['Number of Reviews'][(df_train['City'] == x) & df_train['Number of Reviews']<200 ].hist(bins=1000)\nplt.show()\n\n# sns.pairplot(df_train[['Ranking','Rating']])","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:06:38.248368Z","iopub.execute_input":"2021-10-11T10:06:38.248642Z","iopub.status.idle":"2021-10-11T10:07:03.705884Z","shell.execute_reply.started":"2021-10-11T10:06:38.248599Z","shell.execute_reply":"2021-10-11T10:07:03.704651Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"df_train['Number of Reviews'][(df_train['Number of Reviews'] > 100) ].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:03.707500Z","iopub.execute_input":"2021-10-11T10:07:03.707762Z","iopub.status.idle":"2021-10-11T10:07:04.225691Z","shell.execute_reply.started":"2021-10-11T10:07:03.707717Z","shell.execute_reply":"2021-10-11T10:07:04.224509Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df_train['Number of Reviews'].value_counts().sort_values(ascending=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:04.227312Z","iopub.execute_input":"2021-10-11T10:07:04.227739Z","iopub.status.idle":"2021-10-11T10:07:04.248655Z","shell.execute_reply.started":"2021-10-11T10:07:04.227625Z","shell.execute_reply":"2021-10-11T10:07:04.246988Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за мы этого имеем смещение.\n\n>Подумайте как из этого можно сделать признак для вашей модели. Я покажу вам пример, как визуализация помогает находить взаимосвязи. А далее действуйте без подсказок =) \n","metadata":{}},{"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной","metadata":{}},{"cell_type":"code","source":"df_train['Rating'].value_counts(ascending=True).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:04.254695Z","iopub.execute_input":"2021-10-11T10:07:04.255182Z","iopub.status.idle":"2021-10-11T10:07:04.550313Z","shell.execute_reply.started":"2021-10-11T10:07:04.255095Z","shell.execute_reply":"2021-10-11T10:07:04.548568Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"### Посмотрим распределение целевой переменной относительно признака","metadata":{}},{"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] == 4].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:04.552729Z","iopub.execute_input":"2021-10-11T10:07:04.553005Z","iopub.status.idle":"2021-10-11T10:07:05.098382Z","shell.execute_reply.started":"2021-10-11T10:07:04.552956Z","shell.execute_reply":"2021-10-11T10:07:05.097330Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"df_train['Ranking'][df_train['Rating'] < 5].hist(bins=100)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:05.100454Z","iopub.execute_input":"2021-10-11T10:07:05.101183Z","iopub.status.idle":"2021-10-11T10:07:05.648715Z","shell.execute_reply.started":"2021-10-11T10:07:05.101098Z","shell.execute_reply":"2021-10-11T10:07:05.647175Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"### И один из моих любимых - [корреляция признаков](https://ru.wikipedia.org/wiki/Корреляция)\nНа этом графике уже сейчас вы сможете заметить, как признаки связаны между собой и с целевой переменной.","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(data.drop(['sample'], axis=1).corr(),)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:05.652430Z","iopub.execute_input":"2021-10-11T10:07:05.652880Z","iopub.status.idle":"2021-10-11T10:07:07.114820Z","shell.execute_reply.started":"2021-10-11T10:07:05.652806Z","shell.execute_reply":"2021-10-11T10:07:07.113464Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"Вообще благодаря визуализации в этом датасете можно узнать много интересных фактов, например:\n* где больше Пицерий в Мадриде или Лондоне?\n* в каком городе кухня ресторанов более разнообразна?\n\nпридумайте свои вопрос и найдите на него ответ в данных)","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing\nТеперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию.","metadata":{}},{"cell_type":"code","source":"# на всякий случай, заново подгружаем данные\nDATA_DIR = '/kaggle/input/'\ndf_train = pd.read_csv(DATA_DIR+'sf-dst-restaurant-rating/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'sf-dst-restaurant-rating/kaggle_task.csv')\n\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n\n# # загружаем список городов\ndf_cities = pd.read_csv(DATA_DIR+'cities-of-the-world/cities15000.csv', encoding='latin-1')\n# , encoding='latin-1'\ndf_cities = df_cities[['asciiname','population']]\n\n# загружаем список позитивных и негативных слов \ndf_positive = pd.read_csv(DATA_DIR+'d/nickboyarsky/words-pos-neg/positive-words.txt', encoding='latin-1')\ndf_negative = pd.read_csv(DATA_DIR+'d/nickboyarsky/words-pos-neg/negative-words.txt', encoding='latin-1')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T09:59:27.576298Z","iopub.execute_input":"2021-10-11T09:59:27.577181Z","iopub.status.idle":"2021-10-11T09:59:28.060525Z","shell.execute_reply.started":"2021-10-11T09:59:27.576562Z","shell.execute_reply":"2021-10-11T09:59:28.059790Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Функции, которые я использовал для обработки данных","metadata":{}},{"cell_type":"code","source":"\"\"\"Функция для распарсивания отзывов. Ловим много ошибок в строках.\"\"\"\n# не использовал регулярные выражения, т.к. с ними провозился еще дольше, т.к. для вылавливания ошибок с ними было трудней\ndef parse_reviews_stage1(rev):\n    ''' Получаем reviews в формате:\n    review['reviews_txt'][1] - тексты обзоров\n    review['reviews_dt'][1] - даты обзоров\n    '''\n    if  not pd.isna(rev): \n        # избавляемся от всех неправильных символов\n        rev = str(rev).replace(\"\\\\\\\\\",'-')\n\n        rev = str(rev).replace(\"\\\\'\",'-')\n        rev = str(rev).replace(\"\\\\x7f\",'-')\n        rev = str(rev).replace(\"\\\\xa0\",'-')\n        rev = str(rev).replace(\"', nan]\",'!@, !@ !@]')\n        rev = str(rev).replace(\"[nan, '\",'[!@ !@, !@')\n\n        rev = str(rev).replace(\"['\",'[!@')\n        rev = str(rev).replace(\"[\\\"\",'[!@')\n        rev = str(rev).replace(\"', '\",'!@, !@')\n        rev = str(rev).replace(\"\\\", '\",'!@, !@')\n\n        rev = str(rev).replace(\"', \\\"\",'!@, !@')\n        rev = str(rev).replace(\"\\\", \\\"\",'!@, !@')\n        rev = str(rev).replace(\"']\",'!@]')\n        rev = str(rev).replace(\"\\\"]\",'!@]')\n        \n        rev = str(rev).replace(\"'\",'-')\n        rev = str(rev).replace(\"\\\"\",'-')\n        \n        rev = str(rev).replace(\"!@\",'\\\"')\n        \n        rev = rev.replace('], [', '], \"reviews_dt\": [')\n        rev = '{ \"reviews_txt\":' + rev + '}'\n        rev = rev.replace('[[','[').replace(']]',']')\n\n    return rev\n\ndef parse_reviews(rev):\n    ''' Получаем reviews в формате:\n    review['reviews_txt'][1] - тексты обзоров\n    review['reviews_dt'][1] - даты обзоров\n    '''\n    if  not pd.isna(rev): \n        # парсим получившуюся строку в объекты словарь и список\n        d = json.loads(parse_reviews_stage1(rev))\n        \n        # получаем дату отзыва.\n        d['reviews_dt'] = [dt.datetime.strptime(date, '%m/%d/%Y').date() if len(date.split('/')[2])==4 else dt.datetime.strptime(date, '%m/%d/%y').date() for date in d['reviews_dt']]\n        return d\n    else:\n        return {}\n\n    \n#подсчет плохих и хороших слов в отзывах\ndef rew_words_count(words_series, review_series):\n    word_arr=list(words_series)\n    word_cnt_arr=[]\n    for s1 in review_series:\n        word_count=0\n\n        for w in word_arr:\n            if w.lower() in s1.lower(): word_count += 1\n\n        word_cnt_arr.append(word_count)\n\n#     df_output[count_column_name]=word_cnt_arr\n    return word_cnt_arr\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:03:01.089795Z","iopub.execute_input":"2021-10-11T10:03:01.090160Z","iopub.status.idle":"2021-10-11T10:03:01.111574Z","shell.execute_reply.started":"2021-10-11T10:03:01.090074Z","shell.execute_reply":"2021-10-11T10:03:01.110132Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# df_output=data\n# rew_array=[]\n# for s1 in df_output['Reviews']:\n#     try:\n#         rew_array.append(parse_reviews(s1))\n#     except:\n#         print(s1, parse_reviews_stage1(s1)) # это для поиска строк, на которых парсер падает, и для добавления новых условий замены символов\n\n# df_output['reviews_txt']=pd.DataFrame(rew_array, columns=['reviews_txt'], dtype='datetime64[ns]').astype(str)\n# df_output['reviews_dt']=pd.DataFrame(rew_array, columns=['reviews_dt'], dtype='datetime64[ns]')\n\n# # rew_words_count(df_positive['positive_words'],df_output['reviews_txt'],'good_word_cnt')\n# # rew_words_count(df_negative['negative_words'],df_output['reviews_txt'],'bad_word_cnt')\n\n# data=df_output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Функция обработки данных","metadata":{}},{"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    \n    # ################### 1. Предобработка ############################################################## \n    # убираем не нужные для модели признаки\n    df_output.drop(['ID_TA'], axis = 1, inplace=True)\n    \n    \n    # ################### 2. NAN ############################################################## \n    # Далее заполняем пропуски, вы можете попробовать заполнением средним или средним по городу и тд...\n    data['Number_of_Reviews_isNAN'] = pd.isna(data['Number of Reviews']).astype('uint8')\n    df_output['Number of Reviews'].fillna(0, inplace=True)\n    # тут ваш код по обработке NAN\n    # ....\n    data['Cuisine Style_isNAN'] = pd.isna(data['Cuisine Style']).astype('uint8')\n    df_output['Cuisine Style'].fillna(value=\"['Home kitchen123']\", inplace=True)\n    \n\n \n    # ################### 3. Encoding ############################################################## \n    ##########\n    \"\"\"Нормируем ранк ресторана относительно максимального ранга в его городе\"\"\"\n    city_max_rank=df_output[['Ranking','City']].groupby(by=['City']).max()\n    city_max_rank.columns=['max_rank']\n    df_output=df_output.merge(city_max_rank, how='left', on=['City'])\n    df_output['Ranking2']=df_output['Ranking']/df_output['max_rank']\n\n    \n    \"\"\"Попытался отнормировать также на рейтинге, но это нечестно :-).... хотя MAE получилась 0.038 :-)\"\"\"\n#     city_max_rating_rank=df_output[['Ranking','City','Rating']].groupby(by=['City','Rating']).max()\n#     city_max_rating_rank.columns=['max_rating_rank']\n#     df_output=df_output.merge(city_max_rating_rank, how='left', on=['City','Rating'])\n#     df_output['Ranking_rat']=df_output['Ranking']/df_output['max_rating_rank']\n \n    df_output.drop(['Ranking'], axis = 1, inplace=True)\n    ##########\n    \n    \n    ##########\n    \"\"\"Подсчитываем количество видов кухонь, которые есть в ресторане\"\"\"\n    cousine_cnt=[]\n    for s1 in df_output['Cuisine Style']:\n        cousine_cnt.append(len(json.loads(str(s1).replace(\"'\",'\"'))))\n\n    df_output['Cuisine_count']=cousine_cnt   # Количество кухонь записываем в новый столбец\n    ##########\n    \n    \n    ##########\n    \"\"\"Указываем, является ресторан сетевым или отдельным\"\"\"\n    rest_franshiza=df_output['Restaurant_id'].value_counts()[df_output['Restaurant_id'].value_counts()>1]\n    df_output['set_rest']=df_output['Restaurant_id'].isin(rest_franshiza.index).apply(lambda x: 1 if x==True else 0)\n  \n    \n    \"\"\"Проставляем вместо диапазона цен числовые аналоги и заполняем пустые значения средним значением по городу внутри рейтинга\"\"\"\n    data['Price Range_isNAN'] = pd.isna(data['Price Range']).astype('uint8')\n    df_output['Price Range'] = df_output['Price Range'].replace(['$','$$ - $$$','$$$$'], [1,2,3]).astype(float)\n    city_price_range=df_output[['Price Range','City']].groupby(by=['City']).mean()\n\n    city_price_range.columns=['city_price_range']\n    df_output=df_output.merge(city_price_range, how='left', on=['City'])\n    df_output['Price Range'].fillna(df_output['city_price_range'], inplace=True) \n\n    df_output['Price Range2']=df_output['Price Range']\n    # раскидываем получившиеся ценовые диапазоны, в том числе и средние, на новые столбцы\n    df_output = pd.get_dummies(df_output, columns=['Price Range'], dummy_na=True)\n    \n   \n    \"\"\"для One-Hot Encoding в pandas есть готовая функция - get_dummies. Особенно радует параметр dummy_na\"\"\"\n    df_output['City2']=df_output['City']\n    df_output = pd.get_dummies(df_output, columns=[ 'City2',], dummy_na=True)\n    # тут ваш код не Encoding фитчей\n    # ....\n\n    # ################### 4. Feature Engineering ####################################################\n    # тут ваш код не генерацию новых фитчей\n    # ....\n    \"\"\"Добавляем население городов и нормируем им количество отзывов\"\"\"\n    #добавляем в наш датасет население городов\n    df_cities.drop_duplicates(['asciiname'], inplace=True)\n    df_output=df_output.merge(df_cities, how='left', left_on=['City'], right_on=['asciiname'])\n\n    # двух городов не оказалось в датасете\n    df_cities2=pd.DataFrame(data={'asciiname2': ['Edinburgh', 'Oporto'], 'population2': [488000, 287591]})\n    \n    df_output=df_output.merge(df_cities2, how='left', left_on=['City'], right_on=['asciiname2'])\n    df_output['population'].fillna(value=df_output['population2'], inplace=True)\n    df_output.drop(['asciiname', 'asciiname2','population2'], axis = 1, inplace=True)\n    df_output['population']=df_output['population'].astype(int)\n    df_output['Number of Reviews2']=df_output['Number of Reviews']/df_output['population']\n    \n  \n    \"\"\"Парсим отзывы\"\"\"\n    # парсим строки отзывов в списки с словари и записываем их в столбцы нашего датафрейма    \n    data['Reviews_isNAN'] = df_output['Reviews'].apply(lambda x: 1 if x=='[[], []]' else 0)\n    \n    rew_array=[]\n    for s1 in df_output['Reviews']:\n        try:\n            rew_array.append(parse_reviews(s1))\n        except:\n            print(s1, parse_reviews_stage1(s1)) # это для поиска строк, на которых парсер падает, и для добавления новых условий замены символов\n\n    df_output['reviews_txt']=pd.DataFrame(rew_array, columns=['reviews_txt'], dtype='datetime64[ns]').astype(str)\n    df_output['reviews_dt']=pd.DataFrame(rew_array, columns=['reviews_dt'], dtype='datetime64[ns]')\n    \n    \n    # вычисляем количества плохих и хороших слов (долго выполняется)\n    df_output['good_word_cnt']=rew_words_count(df_positive['positive_words'],df_output['reviews_txt'])\n    df_output['bad_word_cnt']=rew_words_count(df_negative['negative_words'],df_output['reviews_txt'])\n\n    # вычисляем дату последнего отзыва и количество дней между отзывами     \n    df_output['lastReviewDate'] = df_output['Reviews'].apply(lambda x: parse_reviews(x)['reviews_dt'] if not pd.isna(x) else {})\n    df_output['day_between_rew'] = df_output['lastReviewDate'].apply(lambda x: abs(x[1]-x[0]).total_seconds()//86400 if len(x)>1 else 100000)\n    df_output['lastReviewDate'] = df_output['lastReviewDate'].apply(lambda x: sorted(x,reverse=True)[0] if len(x)!=0 else pd.NaT)\n    df_output['lastReviewDate'] = df_output['lastReviewDate'].fillna(dt.date(1950,1,1))\n    df_output['lastReviewDate'] = df_output['lastReviewDate'].apply(lambda x: (dt.datetime.now().date()-x).total_seconds()//86400)\n\n    \n    \n    # ################### 5. Clean #################################################### \n    # убираем признаки которые еще не успели обработать, \n    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n    df_output.drop(object_columns, axis = 1, inplace=True)\n    \n    return df_output\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:04:11.549249Z","iopub.execute_input":"2021-10-11T10:04:11.549565Z","iopub.status.idle":"2021-10-11T10:04:11.588441Z","shell.execute_reply.started":"2021-10-11T10:04:11.549514Z","shell.execute_reply":"2021-10-11T10:04:11.587292Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":">По хорошему, можно было бы перевести эту большую функцию в класс и разбить на подфункции (согласно ООП). ","metadata":{}},{"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось","metadata":{}},{"cell_type":"code","source":"df_preproc = preproc_data(data)\ndf_preproc.sample(10)\ndf_preproc.info()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:04:17.557508Z","iopub.execute_input":"2021-10-11T10:04:17.558027Z","iopub.status.idle":"2021-10-11T10:06:06.079610Z","shell.execute_reply.started":"2021-10-11T10:04:17.557940Z","shell.execute_reply":"2021-10-11T10:06:06.078299Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df_preproc.info()\ndf_preproc.sample(10)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:51.153229Z","iopub.execute_input":"2021-10-11T10:07:51.153800Z","iopub.status.idle":"2021-10-11T10:07:51.210244Z","shell.execute_reply.started":"2021-10-11T10:07:51.153728Z","shell.execute_reply":"2021-10-11T10:07:51.208969Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:51.213161Z","iopub.execute_input":"2021-10-11T10:07:51.213558Z","iopub.status.idle":"2021-10-11T10:07:51.942384Z","shell.execute_reply.started":"2021-10-11T10:07:51.213484Z","shell.execute_reply":"2021-10-11T10:07:51.941607Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**","metadata":{}},{"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:51.943524Z","iopub.execute_input":"2021-10-11T10:07:51.943930Z","iopub.status.idle":"2021-10-11T10:07:51.972647Z","shell.execute_reply.started":"2021-10-11T10:07:51.943889Z","shell.execute_reply":"2021-10-11T10:07:51.971809Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:51.973985Z","iopub.execute_input":"2021-10-11T10:07:51.974653Z","iopub.status.idle":"2021-10-11T10:07:51.982827Z","shell.execute_reply.started":"2021-10-11T10:07:51.974589Z","shell.execute_reply":"2021-10-11T10:07:51.981785Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:51.986664Z","iopub.execute_input":"2021-10-11T10:07:51.986992Z","iopub.status.idle":"2021-10-11T10:07:51.997898Z","shell.execute_reply.started":"2021-10-11T10:07:51.986950Z","shell.execute_reply":"2021-10-11T10:07:51.996729Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"\n# X_test.drop(['max_rating_rank','Ranking_rat',], axis = 1, inplace=True)\n# X_test.info()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:52.000167Z","iopub.execute_input":"2021-10-11T10:07:52.000504Z","iopub.status.idle":"2021-10-11T10:07:52.014846Z","shell.execute_reply.started":"2021-10-11T10:07:52.000452Z","shell.execute_reply":"2021-10-11T10:07:52.013742Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"# Model \nСам ML","metadata":{}},{"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:52.017102Z","iopub.execute_input":"2021-10-11T10:07:52.017481Z","iopub.status.idle":"2021-10-11T10:07:52.199332Z","shell.execute_reply.started":"2021-10-11T10:07:52.017422Z","shell.execute_reply":"2021-10-11T10:07:52.198122Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:52.200753Z","iopub.execute_input":"2021-10-11T10:07:52.201038Z","iopub.status.idle":"2021-10-11T10:07:52.206610Z","shell.execute_reply.started":"2021-10-11T10:07:52.200991Z","shell.execute_reply":"2021-10-11T10:07:52.205490Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:07:52.208029Z","iopub.execute_input":"2021-10-11T10:07:52.208318Z","iopub.status.idle":"2021-10-11T10:08:05.642099Z","shell.execute_reply.started":"2021-10-11T10:07:52.208269Z","shell.execute_reply":"2021-10-11T10:08:05.641230Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:08:05.644013Z","iopub.execute_input":"2021-10-11T10:08:05.644366Z","iopub.status.idle":"2021-10-11T10:08:05.651670Z","shell.execute_reply.started":"2021-10-11T10:08:05.644309Z","shell.execute_reply":"2021-10-11T10:08:05.650716Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(25).plot(kind='barh')","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:08:05.652966Z","iopub.execute_input":"2021-10-11T10:08:05.653448Z","iopub.status.idle":"2021-10-11T10:08:06.209334Z","shell.execute_reply.started":"2021-10-11T10:08:05.653406Z","shell.execute_reply":"2021-10-11T10:08:06.208154Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл","metadata":{}},{"cell_type":"code","source":"test_data.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:08:06.210837Z","iopub.execute_input":"2021-10-11T10:08:06.211094Z","iopub.status.idle":"2021-10-11T10:08:06.249000Z","shell.execute_reply.started":"2021-10-11T10:08:06.211049Z","shell.execute_reply":"2021-10-11T10:08:06.247810Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:08:06.250447Z","iopub.execute_input":"2021-10-11T10:08:06.250713Z","iopub.status.idle":"2021-10-11T10:08:06.257493Z","shell.execute_reply.started":"2021-10-11T10:08:06.250668Z","shell.execute_reply":"2021-10-11T10:08:06.256675Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:08:06.258950Z","iopub.execute_input":"2021-10-11T10:08:06.259251Z","iopub.status.idle":"2021-10-11T10:08:06.281792Z","shell.execute_reply.started":"2021-10-11T10:08:06.259200Z","shell.execute_reply":"2021-10-11T10:08:06.279648Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"predict_submission = model.predict(test_data)\nsample_submission = pd.read_csv(DATA_DIR+'sf-dst-restaurant-rating/sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:10:49.230973Z","iopub.execute_input":"2021-10-11T10:10:49.231343Z","iopub.status.idle":"2021-10-11T10:10:49.459403Z","shell.execute_reply.started":"2021-10-11T10:10:49.231300Z","shell.execute_reply":"2021-10-11T10:10:49.458130Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"predict_submission","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:10:54.065503Z","iopub.execute_input":"2021-10-11T10:10:54.065881Z","iopub.status.idle":"2021-10-11T10:10:54.073456Z","shell.execute_reply.started":"2021-10-11T10:10:54.065828Z","shell.execute_reply":"2021-10-11T10:10:54.072104Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:10:57.157707Z","iopub.execute_input":"2021-10-11T10:10:57.158039Z","iopub.status.idle":"2021-10-11T10:10:57.208957Z","shell.execute_reply.started":"2021-10-11T10:10:57.157986Z","shell.execute_reply":"2021-10-11T10:10:57.207932Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# What's next?\nИли что делать, чтоб улучшить результат:\n* Обработать оставшиеся признаки в понятный для машины формат\n* Посмотреть, что еще можно извлечь из признаков\n* Сгенерировать новые признаки\n* Подгрузить дополнительные данные, например: по населению или благосостоянию городов\n* Подобрать состав признаков\n\nВ общем, процесс творческий и весьма увлекательный! Удачи в соревновании!\n","metadata":{}},{"cell_type":"code","source":"dt.datetime.fromtimestamp(int(os.path.getmtime('submission.csv')))","metadata":{"execution":{"iopub.status.busy":"2021-10-11T10:09:04.632472Z","iopub.execute_input":"2021-10-11T10:09:04.632792Z","iopub.status.idle":"2021-10-11T10:09:04.639381Z","shell.execute_reply.started":"2021-10-11T10:09:04.632742Z","shell.execute_reply":"2021-10-11T10:09:04.638489Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}